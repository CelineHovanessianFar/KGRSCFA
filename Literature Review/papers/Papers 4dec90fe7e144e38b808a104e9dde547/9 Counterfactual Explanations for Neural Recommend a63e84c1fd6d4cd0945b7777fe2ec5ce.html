<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>9: Counterfactual Explanations for Neural Recommenders</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); }
.select-value-color-translucentGray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="a63e84c1-fd6d-4cd0-945b-7777fe2ec5ce" class="page sans"><header><div class="page-header-icon undefined"><img class="icon" src="https://www.notion.so/icons/attachment_lightgray.svg"/></div><h1 class="page-title">9: Counterfactual Explanations for Neural Recommenders</h1><p class="page-description"></p></header><div class="page-body"><p id="92812455-2627-4259-bbbf-2b4db7e5a3e6" class="">Features:</p><ul id="5f9a1077-340a-4471-bb4c-49ad618f68ab" class="bulleted-list"><li style="list-style-type:disc">-</li></ul><hr id="08e0c7ff-53c1-47ab-80fc-d84928c34645"/><p id="2b592609-5fea-4bdd-802d-4e7ed6d0f8fc" class="">The authors developed ACCENT, a framework for generating counterfactual explanations in neural recommender systems by extending influence functions to pairs of items. They adapted the Fast Influence Analysis (FIA) method to efficiently estimate how changes in user-item interactions affect recommendations. This method was validated on two neural models, Neural Collaborative Filtering (NCF) and Relational Collaborative Filtering (RCF), using the MovieLens 100K dataset, demonstrating its ability to produce minimal and meaningful changes that lead to alternative recommendations.</p><hr id="90bfaf78-809a-431c-830f-d5f3920c327a"/><p id="51f6680e-b950-48c5-80ec-e037266ea3b4" class="">This paper introduces ACCENT, a framework for generating counterfactual explanations in neural recommender systems. Unlike previous methods that heavily relied on <mark class="highlight-orange_background">attention mechanisms</mark> or other complex, sometimes unactionable features, ACCENT<mark class="highlight-orange_background"> focuses on a user&#x27;s specific interactions </mark>to provide tangible and scrutable explanations. It extends the idea of influence functions—o<mark class="highlight-orange_background">riginally designed to evaluate the impact of a data point on model training</mark>—to handle pairs of items, identifying training points most relevant to a recommendation. This allows ACCENT to iteratively deduce a<mark class="highlight-orange_background"> counterfactual set: a minimal set of the user&#x27;s actions that, if removed, would lead to a different recommendation.</mark></p><p id="0bb2af7d-d6cc-4ef2-ae21-ca3b9b09a622" class="">The framework is applied to two types of neural recommender models, <mark class="highlight-orange_background">Neural Collaborative Filtering (NCF) </mark>and <mark class="highlight-orange_background">Relational Collaborative Filtering (RCF)</mark>, and is tested on the MovieLens 100K dataset. By adjusting influence functions for deep learning, ACCENT can manage the complexity of neural networks, effectively bridging the gap between traditional, simpler models and more advanced, non-linear systems. The results demonstrate ACCENT&#x27;s feasibility and effectiveness, providing statistically significant improvements in creating smaller and more accurate counterfactual explanations compared to baseline methods.</p><hr id="ca914825-a0b4-4a44-9448-4d0adf161f20"/><h2 id="00e2822e-03d2-4c15-9a8a-1f3090a4e2fd" class="">Technical Aspects</h2><p id="8fb94bf8-fbdd-45f5-86dc-afa95b8a2a18" class="">The technical solution proposed in the paper revolves around the application of influence functions to provide counterfactual explanations in neural recommender systems. Here&#x27;s a breakdown of the key technical components and concepts used in the ACCENT framework:</p><h3 id="04e59325-ce87-4b78-b3fd-a4502c00e0bd" class=""><strong>1. Influence Functions</strong></h3><p id="ebbf08bf-ce4f-4d5b-a8fb-bdb859bf72b6" class="">Influence functions are a<mark class="highlight-orange_background"> statistical tool used to measure how much the change in a single data point&#x27;s weight affects the overall model parameters.</mark> Traditionally, these are used to understand how a small perturbation in the training data impacts the outcome predicted by the model.</p><h3 id="9adb4983-7650-4330-b98d-375bcb6a483a" class=""><strong>2. Extension to Neural Recommenders</strong></h3><p id="28f2edef-72bb-42f4-9ee1-d07a2a5bf649" class="">ACCENT extends the use of influence functions from single data points to pairs of items. This is crucial because, in neural recommenders, the relationships and interactions between items (like products or movies) significantly influence recommendations.</p><h3 id="2b4d29e1-3585-4557-99dd-6756d9d6f51f" class=""><strong>3. Counterfactual Explanation Generation</strong></h3><p id="6372afd0-a192-43ec-8c3d-fcbf9b8ab7f1" class="">The process of generating counterfactual explanations involves the following steps:</p><ul id="bf0824d2-3b3e-418c-a4e9-9c83250aec03" class="bulleted-list"><li style="list-style-type:disc"><strong>Identifying Influence</strong>: ACCENT first calculates how individual user actions (like viewing or rating a movie) influence the recommendation. This is done by estimating how changes in the model parameters affect the predicted recommendation score.</li></ul><ul id="eef1f82f-2005-4857-8624-db9e120a2a5d" class="bulleted-list"><li style="list-style-type:disc"><strong>Pairwise Influence</strong>: <mark class="highlight-orange_background">The influence on the recommendation score difference between two items (a recommended item and its potential replacement) is computed</mark>. This helps in understanding how swapping one item with another affects the recommendation.</li></ul><ul id="346466d4-354f-47ac-963c-906f31d19282" class="bulleted-list"><li style="list-style-type:disc"><strong>Iterative Process</strong>: ACCENT uses this pairwise influence to <mark class="highlight-orange_background">iteratively find a set of user actions that, when hypothetically removed, would lead to a different recommendation</mark>. This set of actions forms the counterfactual explanation.</li></ul><h3 id="5e1426c3-ab74-4da7-b127-cab66e29e45b" class=""><strong>4. Fast Influence Analysis (FIA)</strong></h3><p id="4382e525-6c74-49df-a1fd-e23fbb6e967d" class="">FIA is an adapted method used to compute the influence of removing a data point efficiently, especially in large-scale neural models where computational cost is a concern. ACCENT incorporates FIA to reduce computational demands while maintaining the accuracy of influence estimates.</p><h3 id="8aca7a81-3eaf-41df-a36d-a527e70c6a26" class=""><strong>5. Practical Implementation</strong></h3><p id="08270050-b072-48ce-92e0-a849a2067305" class="">For implementation, ACCENT modifies the typical influence function calculations to fit the neural network context:</p><ul id="d62e7fb7-0fa2-4483-9628-d8af933ea47f" class="bulleted-list"><li style="list-style-type:disc"><strong>Hessian Computation</strong>: The Hessian matrix, which contains second-order derivatives of the loss function with respect to the model parameters, is crucial for calculating influence. However, since neural models can be non-convex and large, ACCENT adds a damping term to ensure that the matrix is invertible.</li></ul><ul id="4ed47243-4626-4c90-b74f-0433b4a37601" class="bulleted-list"><li style="list-style-type:disc"><strong>Influence Estimation</strong>: The influence of removing a user action is calculated by estimating how the removal affects the model parameters, and thus the predicted scores for recommendations.</li></ul><h3 id="c7742ca4-5894-4642-8e61-e0cae0694328" class=""><strong>6. Evaluation and Validation</strong></h3><p id="823add96-1262-4bc0-9e27-7c275b46af0d" class="">ACCENT was validated on the MovieLens 100K dataset using two neural models, NCF and RCF. The framework was compared against baseline methods like attention-based and other influence-based approaches. The evaluation focused on the effectiveness of counterfactual explanations in terms of their size (number of actions in the explanation set) and their impact on recommendation changes.</p><p id="9f900012-4d83-45c2-a91e-1d5c3c5fdb28" class="">Overall, ACCENT provides a robust framework for generating actionable and understandable counterfactual explanations for complex neural recommender systems by leveraging the computational techniques adapted from influence functions and applying them to the specific needs of recommendation models.</p><hr id="7d51395a-ec3f-4221-b92f-34400b6a4b90"/><h2 id="c955dc76-05d9-4b2f-be36-1e7bd07d8eb1" class="">Neural Model and Structural Details</h2><p id="21c74380-ec61-4806-a57a-524aa013c144" class="">the authors use two specific types of neural recommender models: Neural Collaborative Filtering (NCF) and Relational Collaborative Filtering (RCF). Each of these models approaches the recommendation problem with different architectures and data representations:</p><h3 id="031550f9-5482-4265-93b7-b812384cc7c7" class=""><strong>1. Neural Collaborative Filtering (NCF)</strong></h3><p id="5e7b6871-28a4-419d-a05d-d57c2b40a211" class=""><strong>Model Architecture:</strong></p><ul id="363d0a59-b347-4af1-81b4-e82f2fd3cb02" class="bulleted-list"><li style="list-style-type:disc">NCF combines a generalized matrix factorization (GMF) model with a multilayer perceptron (MLP) to learn the non-linear and complex interactions between users and items. This hybrid approach captures both linear interactions (through GMF) and non-linear patterns (through MLP).</li></ul><ul id="d61f1740-7a18-4b24-b384-e2ab4e6bf12b" class="bulleted-list"><li style="list-style-type:disc">The final layer of the model fuses features learned by both GMF and MLP paths to predict the final recommendation score, which is used to determine the most suitable items for a user.</li></ul><p id="58ddf1db-0abc-4f49-b08f-bccf0f939f52" class=""><strong>Data Representation:</strong></p><ul id="e33433d7-c739-43ad-9d26-260eaa0be420" class="bulleted-list"><li style="list-style-type:disc">NCF typically uses user-item interaction data, which is often binary (e.g., click or no click, purchase or no purchase).</li></ul><ul id="b5fcb972-1d15-44ef-acb7-56de271c18fd" class="bulleted-list"><li style="list-style-type:disc">In this study, the input data for NCF is derived from the MovieLens 100K dataset. Ratings are likely binarized, where ratings above a certain threshold (e.g., 3 out of 5) are treated as positive interactions and the rest as negative.</li></ul><h3 id="18e0f706-a6d1-4ab5-8cb1-c21f4c09fab4" class=""><strong>2. Relational Collaborative Filtering (RCF)</strong></h3><p id="3f7a71f1-6641-4a7a-96e4-e24a22acc9a8" class=""><strong>Model Architecture:</strong></p><ul id="d67733fa-50eb-46da-9932-7496f1b723be" class="bulleted-list"><li style="list-style-type:disc">RCF extends the idea of collaborative filtering by incorporating auxiliary information about item-item relations, which helps in learning better item embeddings. This model uses a two-layer attention mechanism to compute target-aware embeddings that reflect not only user-item interactions but also item-item relationships.</li></ul><ul id="028a7593-2e69-497a-af28-1a054776d5c6" class="bulleted-list"><li style="list-style-type:disc">These embeddings are then used to predict the recommendation score, taking into account both direct user-item interactions and the context provided by related items.</li></ul><p id="8a20f79d-f247-4c2e-87e5-bc5e058e0b21" class=""><strong>Data Representation:</strong></p><ul id="91f19909-d757-4e6c-b84a-b99243f86ee5" class="bulleted-list"><li style="list-style-type:disc">RCF uses a richer dataset that includes not only user-item interactions but also item-item relationships. These relationships could be based on similarities between items, such as genre or brand associations.</li></ul><ul id="0aa5dc1e-f3fd-4e74-b409-89ee884d2435" class="bulleted-list"><li style="list-style-type:disc">For the MovieLens dataset, this might include metadata about the movies that relate them to each other, like similar genres, directors, or actors.</li></ul><h3 id="591d7041-77b3-4094-8fd7-65e104789a30" class=""><strong>Additional Technical Details:</strong></h3><p id="deaacc6e-437f-4790-92e5-e5583b2b3862" class=""><strong>Counterfactual Explanation Methodology:</strong></p><ul id="d23adf9e-aefd-4678-bf9c-aa5e096ef168" class="bulleted-list"><li style="list-style-type:disc">Both models incorporate a methodology where they calculate influence scores to determine how specific user actions affect the outcome. These influence scores are derived using Fast Influence Analysis (FIA), adapted for the complexity of neural networks.</li></ul><ul id="a5ca0c2a-936a-4ac0-9964-e3b2bf05f1bd" class="bulleted-list"><li style="list-style-type:disc">ACCENT, the framework developed in the paper, iteratively computes the influence of removing pairs of items (or changing interactions) to generate a minimal set of user actions that, if altered, would lead to a different recommendation. This set is presented as a counterfactual explanation to the user.</li></ul><p id="e7090a61-62c6-4552-b921-1787f2cea473" class=""><strong>Dataset Handling and Preparation:</strong></p><ul id="a0acde78-75c3-4099-9255-904858b0a774" class="bulleted-list"><li style="list-style-type:disc">For RCF, the ratings in the MovieLens dataset are binarized to fit the implicit feedback model, where interactions are either positive (ratings ≥ 3) or negative (ratings &lt; 3).</li></ul><ul id="56015255-32a6-4f82-aa80-a6632517788d" class="bulleted-list"><li style="list-style-type:disc">Users with less than a certain number of positive or negative ratings are pruned to ensure that the remaining user profiles are sufficiently informative for the learning algorithms.</li></ul><p id="8b5da463-23d5-4ad9-b060-3ec323e4244c" class=""><strong>Experimental Setup:</strong></p><ul id="1417ac1a-7159-43a5-96b5-11cf2040f150" class="bulleted-list"><li style="list-style-type:disc">The framework was tested using a subset of the MovieLens 100K dataset, ensuring a balanced and representative sample of user interactions.</li></ul><ul id="e5ecea15-18dd-4ea9-a0d9-4b2656b6d297" class="bulleted-list"><li style="list-style-type:disc">Evaluations compared the effectiveness of ACCENT against several baseline algorithms, using metrics such as the size of the counterfactual explanation set and the percentage of recommendations that changed as intended when the counterfactual actions were hypothetically removed.</li></ul><p id="68325750-eb14-41be-aafd-90067f022f8a" class="">These details highlight the sophisticated nature of the models used and the comprehensive approach taken to develop and validate a method for generating tangible and actionable explanations in neural recommender systems.</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>